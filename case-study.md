# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она требует слишком большого объема памяти.

Была поставлена задача, чтобы за все время обработки рабочего файла программа не занимала более 70 мегабайт оперативной памяти.

# Анализ задачи

Исходный файл имеет размер 130 мегабайт, что уже больше бюджета, а значит чтение и анализ файла надо проводить построчно.
  
## Формирование метрики
Для анализа влияния изменений кода на занимаемую память будем размер замаемой памяти в конце задачи, когда использование памяти максимально. 

В начала работы метрика выглядит так: обработка 20 000 строк занимает 82 Мб памяти.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.


## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 10-20 секунд

Для получения обратной связи я пользуюсь командой которая проверяет корректность работы, потом замеряет
метрику.

ruby task-2.rb && ruby work.rb data20000.txt 

После чего я запускаю профайлер и по его отчету анализирую изменения
 
## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался
- гемом memory_profiler

Вот какие проблемы удалось найти и решить

### Находка №1
- memory_profiler показал, что самую большую часть памяти среди объектов занимают массивы, а среди строчек - наполнение массива сессий 
- отказаться от сбора данных в массивы, а обрабатывать и возвращать от чет по каждому пользователю

- как изменилась метрика
- как изменился отчёт профилировщика

### Ваша находка №2
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика

### Ваша находка №X
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*

## Checklist
- [ ] Построить и проанализировать отчёт гемом `memory_profiler`
- [ ] Построить и проанализировать отчёт `ruby-prof` в режиме `Flat`;
- [ ] Построить и проанализировать отчёт `ruby-prof` в режиме `Graph`;
- [ ] Построить и проанализировать отчёт `ruby-prof` в режиме `CallStack`;
- [ ] Построить и проанализировать отчёт `ruby-prof` в режиме `CallTree` c визуализацией в `QCachegrind`;
- [ ] Построить и проанализировать текстовый отчёт `stackprof`;
- [ ] Построить и проанализировать отчёт `flamegraph` с помощью `stackprof` и визуализировать его в `speedscope.app`;
- [ ] Построить график потребления памяти в `valgrind massif visualier` и включить скриншот в описание вашего `PR`;